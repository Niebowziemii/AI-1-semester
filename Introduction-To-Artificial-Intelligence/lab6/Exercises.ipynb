{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1) Let's consider a linear regression problem with 100 samples described by the formula  $y = a*x+b + noise$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "a = -2\n",
    "b = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x26435851748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-1, 1, n)\n",
    "y = a * x + b + np.random.normal(scale=0.25, size=n)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2) The task is to find the parameters $a$ and $b$. Write a function which calculates loss of the model as a mean square error $ \\frac{(y-\\widehat{y})^2}{n}$ where $y$ is target, $\\widehat{y}$ is output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_target, y_calc):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_2 = 1.1\n",
    "b_2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_calc = a_2 * x + b_2\n",
    "mse(y, y_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, label=\"target\")\n",
    "plt.scatter(x, y_calc, label=\"calculated\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3) Write a function which calculates gradient of loss function, (y_target, and y_calc are tensor not one value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(y_target, y_calc):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4) Fill the update function to calculate gradient of parameter $a$ and $b$ basing on a gradient of loss function (grad_y) and input vector (x).\n",
    "Then update the parameter $a$ and $b$ base on their gradients and learning rate (lr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.a * x + self.b\n",
    "\n",
    "    def update(self, x, grad_y, lr):\n",
    "        #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5) Write Step function which calculates: y_calc output of the model base on input x, loss of the model, gradient of loss, and update the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Step(x, y, model, lr):\n",
    "    #TODO\n",
    "    return y_calc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6) Fit the model for 100 epochs, with learning rate 0.05, and with initial value of parameters a = 1.1, and b = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearLayer(1.1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "losses = []\n",
    "for i in range(epoch):\n",
    "    y_calc, loss = Step(x, y, model, lr)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Animation of the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearLayer(1.1, 2)\n",
    "fig = plt.figure()\n",
    "plt.scatter(x, y)\n",
    "line, = plt.plot(x, y_calc, \".\", c=\"orange\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    y_calc, loss = Step(x, y, model, lr)\n",
    "    line.set_ydata(y_calc)\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "animation.FuncAnimation(fig, animate, np.arange(0, epoch), interval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7) There is an example it can be done in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy array to torch tensor, [:,None] add an additional dimension\n",
    "xt = torch.FloatTensor(x[:, None])\n",
    "yt = torch.FloatTensor(y[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_target, y_calc):\n",
    "    return ((y_target - y_calc) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, a, b):\n",
    "        super(LinearLayer, self).__init__()  # initialize torch functionality\n",
    "        # change a and b to float tensor, and next to parameters,\n",
    "        # the main difference between tensor and parameter is that parameter keeps information about calculations,\n",
    "        # which is used to calculate gradients\n",
    "        self.a = nn.Parameter(torch.FloatTensor([a]).view(1, 1))\n",
    "        self.b = nn.Parameter(torch.FloatTensor([b]))\n",
    "\n",
    "    # forward function is similar to python __call__ but also contain torch functionality\n",
    "    def forward(self, x):\n",
    "        return  x @ self.a + self.b  # linear equation, @ means matrix multiplication for tensor\n",
    "\n",
    "    def update(self, lr):\n",
    "        with torch.no_grad():  # when we update parameter, we have to switch off gradient tracking\n",
    "            self.a.sub_(lr * self.a.grad)  # inplace update of parameter a\n",
    "            self.a.grad.zero_()  # clear gradient\n",
    "\n",
    "            self.b.sub_(lr * self.b.grad)\n",
    "            self.b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  LinearLayer(-1.1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torchStep(x, y, model, lr):\n",
    "    y_calc = model(x)  # calculate the output of our model\n",
    "    loss = mse(y, y_calc)  # calculate the loss\n",
    "    loss.backward()  # calculate all gradients\n",
    "    model.update(lr)  # update parameters\n",
    "    return loss, y_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, y_calc = torchStep(xt, yt, model, lr)\n",
    "y_calc = y_calc.detach().cpu()\n",
    "fig = plt.figure()\n",
    "plt.scatter(xt[:, 0], yt)\n",
    "line, = plt.plot(xt[:, 0], y_calc, c=\"orange\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    loss, y_calc = torchStep(xt, yt, model, lr)\n",
    "    y_calc = y_calc.detach().cpu()  #\n",
    "    line.set_ydata(y_calc)\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "animation.FuncAnimation(fig, animate, np.arange(0, 100), interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use optymalizer to update parameters base on their gradients\n",
    "# the most simple is stochastic gradient descent (SGD)\n",
    "def torchStep2(x, y, model, optim):\n",
    "    optim.zero_grad()  # clear gradients\n",
    "    y_calc = model(x)  # calculate output of model\n",
    "    loss = mse(y, y_calc)  # calculate loss\n",
    "    loss.backward()  # calculate all gradients\n",
    "    optim.step()  # make a optymalizer step which update parameters\n",
    "    return loss, y_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearLayer(-1.1, 0.2)\n",
    "optim = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, y_calc = torchStep2(xt, yt, model, optim)\n",
    "y_calc = y_calc.detach().cpu()\n",
    "fig = plt.figure()\n",
    "plt.scatter(xt[:, 0], yt)\n",
    "line, = plt.plot(xt[:, 0], y_calc, c=\"orange\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    loss, y_calc = torchStep2(xt, yt, model, optim)\n",
    "    y_calc = y_calc.detach().cpu()\n",
    "    line.set_ydata(y_calc)\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "animation.FuncAnimation(fig, animate, np.arange(0, 100), interval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image\n",
    "image = np.array(\n",
    "    [\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Write a function which calculates a convolution on an input matrix (image) using kernel (mask) with shape 3x3 and bias. Do not use padding, so the output image should be in size: (input_wight -2) x (input_height -2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convolution(image, kernel, bias):\n",
    "    img_out = np.zeros((image.shape[0] - 2, image.shape[1] - 2))\n",
    "    #TODO\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel (mask) which is mean filter\n",
    "kernel = np.ones((3, 3)) / 9\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out = Convolution(image, kernel, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Find out kernels (masks) which found horizontal and vertical lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_horizontal ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_horizontal = Convolution(image, kernel_horizontal, 0)\n",
    "plt.imshow(img_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_vertical = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vertical = Convolution(image, kernel_vertical, 0)\n",
    "plt.imshow(img_vertical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3) Complete function to calculate ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Find bias values such that output images pixels have a value above 0 only if original pixel is a part of the horizontal/vertical line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(relu(img_horizontal))\n",
    "plt.show()\n",
    "plt.imshow(relu(img_vertical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Deep network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset\n",
    "df = pd.read_csv('data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n - number of elements in dataset\n",
    "n = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful variables\n",
    "feature_columns = [\"sepal.length\", \"sepal.width\", \"petal.length\", \"petal.width\"]\n",
    "target_column = \"variety\"\n",
    "class_number = 3\n",
    "feature_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries use to map class name to number\n",
    "name_to_class = {0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"}\n",
    "class_to_name = {\"Setosa\": 0, \"Versicolor\": 1, \"Virginica\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion of class name\n",
    "df[target_column] = df[target_column].apply(lambda x: class_to_name[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take raw numpy data\n",
    "x = df[feature_columns].values\n",
    "y = df[target_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data to make network input mean value equals 0 and standard deviation 1\n",
    "x = (x - x.mean(0)) / x.std(0)\n",
    "print(x.mean(0))\n",
    "print(x.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion numpy array to torch tensor\n",
    "x = torch.FloatTensor(x)\n",
    "y = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple neural network with one hidden layer with hidden_nr neuron\n",
    "# input_layer calculate some features  which are used by hidden_layer to calculate prediction\n",
    "# between input_layer and hidden_layer there is relu  as a nonlinear activation function\n",
    "# after hidden_layer there is sigmoid function because we want the network to return the result as a probability of each class in range [0,1]\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_nr, hidden_nr, output_nr):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_nr, hidden_nr)\n",
    "        self.hidden_layer = nn.Linear(hidden_nr, output_nr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy loss is equal $- (y=0) * log(p_0) - (y=1) * log(p_1)  - (y=2) * log(p_2)$ where $p_1, p_2,p_3$ are calculated probability of class 1,2,3; and y=0 means y is classified to class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy means how many samples are classified correctly\n",
    "def Accuracy(y_target, y_calc):\n",
    "    prediction_class = y_calc.max(1)[1]\n",
    "    number_of_correct = (prediction_class == y).float().sum()\n",
    "    return number_of_correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Step(x, y, model, optim):\n",
    "    optim.zero_grad()\n",
    "    y_calc = model(x)\n",
    "    loss = loss_func(y_calc, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    acc = Accuracy(y, y_calc)\n",
    "    return loss, y_calc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function train model for epoch step, and collect metrics (loss and accuracy)\n",
    "def Train(x, y, model, optim, epoch):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i in range(epoch):\n",
    "        loss, y_calc, acc = Step(x, y, model, optim)\n",
    "        losses.append(loss)\n",
    "        accuracies.append(acc)\n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model and optimalizer\n",
    "hidden_nr = 5\n",
    "model = Net(feature_number, hidden_nr, class_number)\n",
    "optim = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200\n",
    "losses, accuracies = Train(x, y, model, optim, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task for 5:\n",
    "Choose one of the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1) Create a report of testing different values of learning rate, and number of neurons in hidden layer; Run every test 10 times with 200 epochs. Make a plot of mean of losses and accuracy of each value in the test case. Make a table of score after 200 epochs of learning which should contain best, worst, mean and standard deviation of loss and accuracy (you can use pandas describe function).  \n",
    "\n",
    "    test case 1: \n",
    "    learning rate:[ 1, 0.5, 0.1, 0.01, 0.001]\n",
    "    number of neuron in hidden layer: 10\n",
    "    \n",
    "    test case 2: \n",
    "    number of neuron in hidden layer: [1, 2, 5, 10, 20, 100]\n",
    "    learning rate: 0.1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2) If you have a GPU, you can try to make an image classifier shown inhttps://course.fast.ai/videos/?lesson=2\n",
    "You should watch all video, but after 16.30 there are creating your own dataset and next create an image classifier.\n",
    "You can use animals dataset or prepare your own dataset, but it should contain at least 4 different classes.\n",
    "\n",
    "    To finish this task you should prepare a report by creating a classifier, and show working neural network at the laboratory.\n",
    "    The report should contain:\n",
    "        - describe of dataset: number of samples, some examples, how it was prepared, number of samples in train and validation set, are there images which contains more than one class, batch size\n",
    "        - describe of model: tested models\n",
    "        - describe of training: how testing looks like, how many epoch, how long it takes, data cleaning, learning rate finder and so on, plots of losses, and accuracy\n",
    "        - describe of result: confusion matrix, examples of correct classified image, examples of incorrect classified image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
